{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0211d170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (314, 14)\n",
      "Target variable distribution:\n",
      "diabetes_diagnosed\n",
      "0    211\n",
      "1    103\n",
      "Name: count, dtype: int64\n",
      "Diabetes prevalence: 32.80%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "df = pd.read_csv(\"../data/cleaned_responses.csv\")\n",
    "\n",
    "print(\"Original dataset shape:\", df.shape)\n",
    "print(\"Target variable distribution:\")\n",
    "print(df['diabetes_diagnosed'].value_counts())\n",
    "print(f\"Diabetes prevalence: {(df['diabetes_diagnosed'].sum() / len(df)) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e117f081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (314, 13)\n",
      "Features used: ['gender', 'pregnancies', 'age', 'glucose', 'blood_pressure', 'weight', 'height', 'insulin', 'bmi', 'physically_active', 'smoking', 'junk_food', 'family_history']\n",
      "Class weights: {0: 0.742603550295858, 1: 1.5304878048780488}\n"
     ]
    }
   ],
   "source": [
    "# Feature selection and preparation\n",
    "\n",
    "feature_cols = ['gender', 'pregnancies', 'age', 'glucose', 'blood_pressure', \n",
    "                'weight', 'height', 'insulin', 'bmi', 'physically_active', \n",
    "                'smoking', 'junk_food', 'family_history']\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df['diabetes_diagnosed'].astype(int).copy()\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Features used: {feature_cols}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Feature scaling \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Compute class weights to handle imbalance\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = {int(cls): float(w) for cls, w in zip(classes, class_weights)}\n",
    "print(\"Class weights:\", class_weight_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33d22393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,969</span> (15.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,969\u001b[0m (15.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,745</span> (14.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,745\u001b[0m (14.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the ANN model\n",
    "\n",
    "def build_ann(input_dim: int) -> Sequential:\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(16, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "            tf.keras.metrics.Precision(name='precision'),\n",
    "            tf.keras.metrics.Recall(name='recall'),\n",
    "            tf.keras.metrics.AUC(name='auc')\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_ann(X_train_scaled.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68bdfbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8500 - auc: 0.9152 - loss: 0.3732 - precision: 0.7179 - recall: 0.8750 - val_accuracy: 0.9804 - val_auc: 0.9848 - val_loss: 0.2223 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8850 - auc: 0.9503 - loss: 0.2925 - precision: 0.7662 - recall: 0.9219 - val_accuracy: 0.9804 - val_auc: 0.9857 - val_loss: 0.2157 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8350 - auc: 0.9205 - loss: 0.3622 - precision: 0.7123 - recall: 0.8125 - val_accuracy: 0.9804 - val_auc: 0.9848 - val_loss: 0.2097 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8700 - auc: 0.9588 - loss: 0.2747 - precision: 0.7500 - recall: 0.8906 - val_accuracy: 0.9804 - val_auc: 0.9857 - val_loss: 0.2034 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8600 - auc: 0.9424 - loss: 0.3068 - precision: 0.7250 - recall: 0.9062 - val_accuracy: 0.9804 - val_auc: 0.9857 - val_loss: 0.1974 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8900 - auc: 0.9454 - loss: 0.2983 - precision: 0.7838 - recall: 0.9062 - val_accuracy: 0.9804 - val_auc: 0.9865 - val_loss: 0.1937 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8950 - auc: 0.9591 - loss: 0.2664 - precision: 0.7722 - recall: 0.9531 - val_accuracy: 0.9804 - val_auc: 0.9874 - val_loss: 0.1886 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8800 - auc: 0.9484 - loss: 0.2875 - precision: 0.7632 - recall: 0.9062 - val_accuracy: 0.9804 - val_auc: 0.9865 - val_loss: 0.1854 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8900 - auc: 0.9490 - loss: 0.2982 - precision: 0.7917 - recall: 0.8906 - val_accuracy: 0.9804 - val_auc: 0.9874 - val_loss: 0.1820 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8200 - auc: 0.9282 - loss: 0.3506 - precision: 0.6750 - recall: 0.8438 - val_accuracy: 0.9804 - val_auc: 0.9874 - val_loss: 0.1783 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8750 - auc: 0.9513 - loss: 0.2918 - precision: 0.7532 - recall: 0.9062 - val_accuracy: 0.9804 - val_auc: 0.9874 - val_loss: 0.1746 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8650 - auc: 0.9389 - loss: 0.3176 - precision: 0.7467 - recall: 0.8750 - val_accuracy: 0.9804 - val_auc: 0.9882 - val_loss: 0.1717 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8800 - auc: 0.9411 - loss: 0.3168 - precision: 0.7703 - recall: 0.8906 - val_accuracy: 0.9804 - val_auc: 0.9882 - val_loss: 0.1705 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - auc: 0.9589 - loss: 0.2729 - precision: 0.7973 - recall: 0.9219 - val_accuracy: 0.9804 - val_auc: 0.9891 - val_loss: 0.1664 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9100 - auc: 0.9579 - loss: 0.2649 - precision: 0.8026 - recall: 0.9531 - val_accuracy: 0.9804 - val_auc: 0.9891 - val_loss: 0.1635 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9000 - auc: 0.9655 - loss: 0.2593 - precision: 0.8235 - recall: 0.8750 - val_accuracy: 0.9804 - val_auc: 0.9907 - val_loss: 0.1612 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8800 - auc: 0.9516 - loss: 0.2878 - precision: 0.7778 - recall: 0.8750 - val_accuracy: 0.9804 - val_auc: 0.9899 - val_loss: 0.1609 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8950 - auc: 0.9573 - loss: 0.2686 - precision: 0.7945 - recall: 0.9062 - val_accuracy: 0.9804 - val_auc: 0.9882 - val_loss: 0.1603 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8950 - auc: 0.9594 - loss: 0.2703 - precision: 0.7945 - recall: 0.9062 - val_accuracy: 0.9804 - val_auc: 0.9891 - val_loss: 0.1579 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - auc: 0.9416 - loss: 0.3168 - precision: 0.7826 - recall: 0.8438 - val_accuracy: 0.9804 - val_auc: 0.9899 - val_loss: 0.1571 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9375 - auc: 1.0000 - loss: 0.1726 - precision: 1.0000 - recall: 0.8333\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8850 - auc: 0.9469 - loss: 0.2835 - precision: 0.7808 - recall: 0.8906 - val_accuracy: 0.9804 - val_auc: 0.9891 - val_loss: 0.1559 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8950 - auc: 0.9633 - loss: 0.2547 - precision: 0.7945 - recall: 0.9062 - val_accuracy: 0.9804 - val_auc: 0.9882 - val_loss: 0.1560 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8750 - auc: 0.9530 - loss: 0.2847 - precision: 0.7600 - recall: 0.8906 - val_accuracy: 0.9804 - val_auc: 0.9882 - val_loss: 0.1544 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9200 - auc: 0.9795 - loss: 0.2128 - precision: 0.8243 - recall: 0.9531 - val_accuracy: 0.9804 - val_auc: 0.9882 - val_loss: 0.1545 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8950 - auc: 0.9592 - loss: 0.2642 - precision: 0.8028 - recall: 0.8906 - val_accuracy: 0.9804 - val_auc: 0.9882 - val_loss: 0.1543 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.1059 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9050 - auc: 0.9639 - loss: 0.2528 - precision: 0.7922 - recall: 0.9531 - val_accuracy: 0.9804 - val_auc: 0.9882 - val_loss: 0.1525 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8950 - auc: 0.9400 - loss: 0.3155 - precision: 0.7945 - recall: 0.9062 - val_accuracy: 0.9804 - val_auc: 0.9882 - val_loss: 0.1531 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9050 - auc: 0.9623 - loss: 0.2576 - precision: 0.8261 - recall: 0.8906 - val_accuracy: 0.9804 - val_auc: 0.9882 - val_loss: 0.1522 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8600 - auc: 0.9371 - loss: 0.3128 - precision: 0.7500 - recall: 0.8438 - val_accuracy: 0.9804 - val_auc: 0.9882 - val_loss: 0.1508 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8900 - auc: 0.9586 - loss: 0.2683 - precision: 0.8000 - recall: 0.8750 - val_accuracy: 0.9804 - val_auc: 0.9882 - val_loss: 0.1519 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9375 - auc: 0.9833 - loss: 0.1955 - precision: 0.8571 - recall: 1.0000\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9100 - auc: 0.9640 - loss: 0.2570 - precision: 0.8108 - recall: 0.9375 - val_accuracy: 0.9804 - val_auc: 0.9882 - val_loss: 0.1505 - val_precision: 0.9474 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Train the model with callbacks\n",
    "\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_auc', mode='max', patience=15, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_auc', mode='max', factor=0.5, patience=5, min_lr=1e-5, verbose=1),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ab8fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      "ANN Model Performance Metrics:\n",
      "Accuracy: 0.9206\n",
      "Precision: 0.8333\n",
      "Recall: 0.9524\n",
      "F1-Score: 0.8889\n",
      "AUC-ROC: 0.9694\n",
      "\n",
      "Confusion Matrix:\n",
      "[[38  4]\n",
      " [ 1 20]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.94        42\n",
      "           1       0.83      0.95      0.89        21\n",
      "\n",
      "    accuracy                           0.92        63\n",
      "   macro avg       0.90      0.93      0.91        63\n",
      "weighted avg       0.93      0.92      0.92        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "\n",
    "y_pred_proba = model.predict(X_test_scaled).ravel()\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"\\nANN Model Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ac0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# 1. Training curves\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Binary Crossentropy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history.history['auc'], label='Train AUC')\n",
    "plt.plot(history.history['val_auc'], label='Val AUC')\n",
    "plt.title('AUC Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "\n",
    "# 2. ROC curve\n",
    "plt.subplot(2, 2, 3)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "\n",
    "# 3. Confusion matrix heatmap\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples', \n",
    "            xticklabels=['No Diabetes', 'Diabetes'],\n",
    "            yticklabels=['No Diabetes', 'Diabetes'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c46f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model and artifacts\n",
    "\n",
    "model_path = \"/Users/91life/Desktop/diabetes-project/models/\"\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# Save Keras model in native format\n",
    "model.save(f\"{model_path}ann_model.keras\")\n",
    "# Also save as H5 for compatibility\n",
    "model.save(f\"{model_path}ann_model.h5\")\n",
    "\n",
    "# Save scaler and feature columns\n",
    "joblib.dump(scaler, f\"{model_path}scaler_ann.pkl\")\n",
    "joblib.dump(feature_cols, f\"{model_path}feature_columns_ann.pkl\")\n",
    "\n",
    "print(f\"\\nANN model and artifacts saved to: {model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
